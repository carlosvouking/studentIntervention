
\documentclass[12pt]{article}
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath}
\usepackage{etoolbox}
\usepackage{changepage}
\usepackage{titlesec}
\usepackage[parfill]{parskip}
\usepackage[margin=1in]{geometry}
\usepackage{times}
\usepackage[numbers,super]{natbib}
\usepackage{enumitem} %get rid of spaces in listened

% For the images and graphics
\usepackage{subfig} % For subfigures in floats
\usepackage[section]{placeins}
\makeatletter
 \@ifpackageloaded{tex4ht}{%
\usepackage[dvips]{color,graphicx}
    \usepackage[tex4ht]{hyperref}
    }{%
      \usepackage[pdftex]{graphicx}
      \usepackage{hyperref}
          }
\makeatother
\graphicspath{ {/Users/omojumiller/mycode/MachineLearningNanoDegree/Machine-Learning-Project/studentIntervention/images/} } %Path to images


% For cutesy tables
\usepackage{multirow}
\usepackage[table]{xcolor}
\usepackage{longtable}
\usepackage{array}
\usepackage{booktabs} % To draw thick lines in table.
\usepackage{tablefootnote} % To allow footnotes in table.
\newcommand{\nextitem}{\par\hspace {\labelsep} \textendash \hspace {\labelsep}} % For list inside table cell

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}


 % For text right arrow in chapter 1
 \usepackage{textcomp}
 
 % For highlighted paragraphs
\usepackage{xcolor}
\usepackage{tcolorbox}

% For listing code

% Default fixed font does not support bold face
\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{10} % for bold 
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{10}  % for normal
% Custom colors
\usepackage{color}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}


\usepackage{listings}


 % Python style for highlighting
\newcommand\pythonstyle{\lstset{
language=Python,
basicstyle=\ttm,
otherkeywords={self},             % Add keywords here
keywordstyle=\ttb\color{deepblue},
emph={MyClass,__init__},          % Custom highlighting
emphstyle=\ttb\color{deepred},    % Custom highlighting style
stringstyle=\color{deepgreen},
frame=tb,                         % Any extra options here
showstringspaces=false            % 
}}


% Python environment
\lstnewenvironment{python}[1][]
{
    \pythonstyle
    \lstset{#1}
}
{}

% Python for external files
\newcommand\pythonexternal[2][]{{
\pythonstyle
\lstinputlisting[#1]{#2}}}

% Python for inline
\newcommand\pythoninline[1]{{\pythonstyle\lstinline!#1!}}

%----------------------------------------------------------------------------------------
%  TITLE SECTION
%----------------------------------------------------------------------------------------
\title{\large \textbf{Building a Student Intervention System: An Udacity Nanodegree ML Project}} % using \large makes the title approximately 14 pt.
% Author info isn't included for the Annual Conference but some regional conferences might request it.
\author{Omoju Miller}
%\author{\normalsize Author Name\\
%\normalsize email@example.com\\
%\normalsize Name of Your Department\\\
%\normalsize Your Institution Name}
\date{\today} % This leaves the date blank.

\makeatletter % This gets the margins for the title set.
\patchcmd{\@maketitle}{\begin{center}}{\begin{adjustwidth}{0.5in}{0.5in}\begin{center}}{}{}
\patchcmd{\@maketitle}{\end{center}}{\end{center}\end{adjustwidth}}{}{}
\makeatother

\begin{document}
\raggedright
\maketitle
\thispagestyle{empty}
\pagestyle{empty}



%----------------------------------------------------------------------------------------
%  PAPER CONTENTS
%----------------------------------------------------------------------------------------
\section*{Introduction}
Your goal is to identify students who might need early intervention - which type of supervised machine learning problem is this, classification or regression? Why?

\begin{itemize}[noitemsep,nolistsep]
\item 
This task sounds like a problem that would be best suited for a classification algorithm. The inherent task is to develop a learners that can "predicting a category." If we look at the problem from another perspective, we can consider the student data available as a ``labeled'' dataset. We have features that we can use to determine who has succeeded in the class versus who has not. For that insight, we could use `\pythoninline{passed}' column as our class label.
\end{itemize}


\section*{Models}
For the student intervention challenge, three supervised learning algorithms have been selected as appropriate learners for the task. The algorithms are as follows:
\begin{enumerate}[noitemsep,nolistsep]
\item Decision tree classifier
\item Support vector machines
\item Random forest classifier
\end{enumerate}


%-------------------------------DECISION TREE CLASSIFIER----------------------------------%

\subsection*{Decision Tree Classifier}
\begin{itemize} [noitemsep,nolistsep]
\item What is the theoretical $O(n)$ time \& space complexity in terms of input size?\\ 
The theoretical time \& space complexity of decision trees classifiers as implemented in sci-kit learn package is $O(n_{features} n^2_{samples} log(n_{samples}))$.
\item What are the general applications of this model? What are its strengths and weaknesses?\\ 
The decision tree algorithm is usually applied to classification and regression problems. 
       \begin{itemize}[noitemsep,nolistsep]
       \item Advantages of decision trees:
              \begin{itemize}[noitemsep,nolistsep]
                     \item Very intuitive. You can look at the results and understand it. 
                     \item Requires little data preparation. 
                     \item The cost of using the tree (i.e., predicting data) is logarithmic in the number of data points used to train the tree.
                     \item Able to handle both numerical and categorical data.
                     \item Is an explainable algorithm---a white ox model. If a given situation is observable in a model, the explanation for the condition is easily explained by boolean logic.
                     \item Possible to validate a model using statistical tests. 
                     \item Very robust. Performs well even if its assumptions are somewhat violated by the true model from which the data were generated.
              \end{itemize}
       \item Disadvantages of decision trees:
              \begin{itemize}[noitemsep,nolistsep]
                     \item Decision-tree learners can create over-complex trees that do not generalize the data well. They are prone to over-fitting especially in the case of data with lots of features.
                     \item Decision trees can be unstable because small variations in the data might result in a completely different tree being generated. 
                     \item The problem of learning an optimal decision tree is known to be NP-complete under several aspects of optimality and even for simple concepts. 
                     \item There are concepts that are hard to learn because decision trees do not express them easily, such as XOR, parity or multiplexer problems.
                     \item Decision tree learners create biased trees if some classes dominate. 
              \end{itemize}
       \end{itemize}


\item Given what you know about the data so far, why did you choose this model to apply?\\
The decision tree classifier was chosen because of its ease of use and its relatively cheap time complexity.\\
Another \textit{major} reason why the decision tree classifier was selected was its ease of interpretation of the classifier results. For this problem domain, it isn't just satisfactory to identify students that need intervention, what learning researchers ultimately want is to gain \textit{insights} into the nature of learning, and the social factors that lead to certain outcomes for at-risk students. A decision tree learner, with its ability to graphically plot out the tree becomes a research tool in the hands of learning scientist. Consequently, this can help the school board of supervisors build better solutions for those students which well executed could potentially reduce the costs associated with remediating failed students.
\end{itemize} 


\setlength{\extrarowheight}{1.5pt}
\begin{table}[!htbp]
\caption{Result of training with a DecisionTreeClassifier} %title of the table
\centering % centering table
\begin{tabular}{|p{6cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|} % creating four columns
\hline % inserts single-line
& \multicolumn{3}{c|}{Training set size}\\[5pt]
\cline{2-4} 
& 100 & 200 & 300\\[0.5ex]
\hline % inserts single-line

Training time (secs)   &       0.001 & 0.001 & 0.002 \\
Prediction time (secs)   &     0.000 & 0.000 & 0.000 \\
F1 score for training set  &   1.000 & 1.000 & 1.000 \\
F1 score for test set    &     0.737 & 0.775 & 0.690 \\
\hline % inserts single-line
\end{tabular}
\label{decisionTreeTable}
\end{table}


\setlength{\extrarowheight}{1.5pt}
\begin{table}[!htbp]
\caption{DecisionTreeClassifier - Confusion Matrix} %title of the table
\centering % centering table
\begin{tabular}{ |l|l|p{3cm}|p{3cm}| }
\hline % inserts single-line
\multirow{2}{*}{} & & \multicolumn{2}{c|}{Actual Class} \\ 
\cline{3-4}
\multirow{2}{*}{} & & Passed & Fail \\ 
\hline
\multirow{2}{1.5in}{Predicted Class} & Passed & 19.000 & 14.000 \\ 
%\cline{2-2}
 & Fail & 22.000 & 40.000  \\ \hline
\end{tabular}
\end{table}


%-------------------------------------------S V M -----------------------------------------%

\subsection*{Support Vector Machine}
\begin{itemize} [noitemsep,nolistsep]
\item What is the theoretical $O(n)$ time \& space complexity in terms of input size?
\item What are the general applications of this model? What are its strengths and weaknesses?
\item Given what you know about the data so far, why did you choose this model to apply?
\end{itemize} 


\setlength{\extrarowheight}{1.5pt}
\begin{table}[!htbp]
\caption{Result of training with a Support Vector Machine} %title of the table
\centering % centering table
\begin{tabular}{|p{6cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|} % creating four columns
\hline % inserts single-line
& \multicolumn{3}{c|}{Training set size}\\[5pt]
\cline{2-4} 
& 100 & 200 & 300\\[0.5ex]
\hline % inserts single-line

Training time (secs)   &       0.008 & 0.010 & 0.051 \\
Prediction time (secs)   &     0.000 & 0.000 & 0.000 \\
F1 score for training set  &   0.909 & 0.853 & 0.830 \\
F1 score for test set    &     0.767 & 0.769 & 0.779 \\
\hline % inserts single-line
\end{tabular}
\label{svmTable}
\end{table}

%-----------------------------RANDOM FOREST CLASSIFIER---------------------------------------%

\subsection*{Random Forest Classifier}
\begin{itemize} [noitemsep,nolistsep]
\item What is the theoretical $O(n)$ time \& space complexity in terms of input size?
\item What are the general applications of this model? What are its strengths and weaknesses?
\item Given what you know about the data so far, why did you choose this model to apply?
\end{itemize} 


\setlength{\extrarowheight}{1.5pt}
\begin{table}[!htbp]
\caption{Result of training with a Random Forest Classifier} %title of the table
\centering % centering table
\begin{tabular}{|p{6cm}|p{1.5cm}|p{1.5cm}|p{1.5cm}|} % creating four columns
\hline % inserts single-line
& \multicolumn{3}{c|}{Training set size}\\[5pt]
\cline{2-4} 
& 100 & 200 & 300\\[0.5ex]
\hline % inserts single-line

Training time (secs)   &       0.029 & 0.020 & 0.026 \\
Prediction time (secs)   &     0.000 & 0.000 & 0.000 \\
F1 score for training set  &   0.984 & 0.989 & 0.997 \\
F1 score for test set    &     0.722 & 0.774 & 0.694 \\
\hline % inserts single-line
\end{tabular}
\label{randomForestClassifierTable}
\end{table}

%----------------------------------------------------------------------------------------

\section*{Best Model}
Based on the experiments you performed earlier, in 1-2 paragraphs explain to the board of supervisors what single model you chose as the best model. Which model is generally the most appropriate based on the available data, limited resources, cost, and performance?

In 1-2 paragraphs explain to the board of supervisors in layman's terms how the final model chosen is supposed to work (for example if you chose a Decision Tree or Support Vector Machine, how does it make a prediction).

Fine-tune the model. Use Gridsearch with at least one important parameter tuned and with at least 3 settings. Use the entire training set for this.
What is the model's final F1 score?


\section*{Conclusion}

This paper has laid out some of the challenge of 













%----------------------------------------------------------------------------------------

\end{document}  